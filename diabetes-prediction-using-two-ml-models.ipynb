{"cells":[{"metadata":{},"cell_type":"markdown","source":"**TO PREDICT THE DIABETES USING THE PIMA DIABETES DATASET from Kaggle**"},{"metadata":{},"cell_type":"markdown","source":"**OBJECTIVE:** The dataset is to diagnostically predict whether a patient has diabetes or not based on certain diagnostic measurements such as the number of pregnancies the patient has had, their BMI, insulin level, age etc. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage."},{"metadata":{},"cell_type":"markdown","source":"There is one **TARGET** variable (Dependent feature), \"Outcome\" and **PREDICTOR** variables (Independent features) includes \"the number of pregnancies the patient has had, their BMI, insulin level, age, glucose, bloodpressure, skinthickness, diabetespedigreefunction\"."},{"metadata":{},"cell_type":"markdown","source":"**Using the Random forest and Xgbooster algorithm**"},{"metadata":{},"cell_type":"markdown","source":"**IMPORTING LIBRARIES**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**How to read a CSV file**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data=pd.read_csv(\"/kaggle/input/pima-indians-diabetes-database/diabetes.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**How to find the total rows and columns in a dataset**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**How to print the first 5 rows and columns in dataset**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Finding the number of ones and zeros from \"Outcome\" column**"},{"metadata":{"trusted":true},"cell_type":"code","source":"Outcome_1_count = len(data.loc[data['Outcome']== 1])\nOutcome_0_count = len(data.loc[data['Outcome']== 0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**The dataset is not imbalanced for the algorithms that we are using (Random forest and XGBooster)**"},{"metadata":{"trusted":true},"cell_type":"code","source":"(Outcome_1_count,Outcome_0_count)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Checking if we have Null values in the dataset**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().values.any()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Finding the correlation using heatmap (Seaborn Library)**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\ncorrmat=data.corr()\ntop_corr_features= corrmat.index\nplt.figure(figsize=(10,10))\n#Plotting heatmap\ng=sns.heatmap(data[top_corr_features].corr(),annot=True,cmap='RdYlGn')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**If we want just the correlation data with just the numeric values, We use the below function**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Checking for other missing zeros values in the dataset by checking each column**"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Total number of rows:{0}\".format(len(data)))\nprint(\"Number of rows missing Pregnancies:{0}\".format((len(data.loc[data['Pregnancies']==0]))))\nprint(\"Number of rows missing Glucose:{0}\".format((len(data.loc[data['Glucose']==0]))))\nprint(\"Number of rows missing BloodPressure:{0}\".format((len(data.loc[data['BloodPressure']==0]))))\nprint(\"Number of rows missing SkinThickness:{0}\".format((len(data.loc[data['SkinThickness']==0]))))\nprint(\"Number of rows missing Insulin:{0}\".format((len(data.loc[data['Insulin']==0]))))\nprint(\"Number of rows missing BMI:{0}\".format((len(data.loc[data['BMI']==0]))))\nprint(\"Number of rows missing DiabetesPedigreeFunction:{0}\".format((len(data.loc[data['DiabetesPedigreeFunction']==0]))))\nprint(\"Number of rows missing Age:{0}\".format((len(data.loc[data['Age']==0]))))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Train_Test_split**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfeature_columns=['Pregnancies','Glucose','BloodPressure','SkinThickness','Insulin','BMI','DiabetesPedigreeFunction','Age']\npredicted_class=['Outcome']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X= data[feature_columns].values\ny= data[predicted_class].values\n\n# Performing the split \nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.30,random_state=10)\n# ( when we want to make a split, we might get a different set of train and test data points and will not help you in debugging in case we get an issue.So,we use random_state in train_test_split)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Displaying the shape and we can infer that 30% of the data is test data and 70% of the data is train data because we have test_size as 0.30.\nprint(X_train.shape)\nprint(X_test.shape)\n\nprint(y_train.shape)\nprint(y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Impution** is used where the missing values can be imputed with a provided constant value, or using the statistics (mean, median or most frequent) of each column in which the missing values are located.\nIn this case, We will be taking the \"mean\""},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.impute import SimpleImputer\nfill_values= SimpleImputer(missing_values=0,strategy='mean')\nX_train= fill_values.fit_transform(X_train)\nX_test=fill_values.fit_transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Applying **RandomForest** algorithm\n  ravel() function: It returns contiguous flattened array(1D array with all the input-array elements and with the same type as it). A copy is made only if needed."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrandom_forest_model= RandomForestClassifier(random_state=2)\n#(When we use 42 as random_state, we will always get the same output the first time we make the split. \n# This is useful if we want reproducible results)\n\nrandom_forest_model.fit(X_train,y_train.ravel())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finding the **Accuracy** of the RandomForest algorithm"},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_train_data=random_forest_model.predict(X_test)\nfrom sklearn import metrics\nprint(\"Accuracy={0:3f}\".format(metrics.accuracy_score(y_test,predict_train_data)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**XGBCLASSIFIER Algorithm**"},{"metadata":{},"cell_type":"markdown","source":"**Hyperparameter optimization:**\n  It is a single set of well-performing hyperparameters that we can use to configure your model."},{"metadata":{},"cell_type":"markdown","source":"**Below are the Booster Parameters**"},{"metadata":{"trusted":true},"cell_type":"code","source":"params={\n    \"learning_rate\" : [0.05,0.10,0.15,0.20,0.25,0.30], \n    \"max_depth\"     : [3,4,5,6,8,10,9,7],\n    \"min_child_weight\": [1,3,5,7],\n    \"gamma\":[0.0,0.1,0.2,0.3,0.4],\n    \"colsample\":[0.3,0.4,0.5,0.7] \n    \n}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Hyperparameter optimization using RandomizedSearchCV**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\nimport xgboost","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier=xgboost.XGBClassifier()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_search=RandomizedSearchCV(classifier,param_distributions=params,n_iter=5,scoring=\"roc_auc\",n_jobs=-1,cv=5,verbose=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def timer(start_time=None):\n    if not start_time:\n        start_time = datetime.now()\n        return start_time\n    elif start_time:\n        thour,temp_sec = divmod((datetime.now()- start_time).total_seconds(),3600)\n        tmin,tsec = divmod(temp_sec,60)\n        print('\\n Time taken: %i hour %i minutes and %s seconds.'% (thour,tmin,round(tsec,2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from datetime import datetime\nstart_time=timer(None)\nrandom_search.fit(X_train,y_train.ravel())\ntimer(start_time)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Finding the best estimator for XGBclassifier**"},{"metadata":{"trusted":true},"cell_type":"code","source":"random_search.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier=xgboost.XGBClassifier(base_score=0.5, booster='gbtree', colsample=0.7,\n              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n              gamma=0.4, gpu_id=-1, importance_type='gain',\n              interaction_constraints='', learning_rate=0.05, max_delta_step=0,\n              max_depth=10, min_child_weight=5, missing=0,\n              monotone_constraints='()', n_estimators=100, n_jobs=4,\n              num_parallel_tree=1, random_state=0, reg_alpha=0, reg_lambda=1,\n              scale_pos_weight=1, subsample=1, tree_method='exact',\n              validate_parameters=1, verbosity=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nlabelencoder_X = LabelEncoder()\nX[:, 0] = labelencoder_X.fit_transform(X[:, 0])\ntransformer = ColumnTransformer([('one_hot_encoder', OneHotEncoder(), [0])],remainder='passthrough')\nX = np.array(transformer.fit_transform(X), dtype=np.float)\nlabelencoder_Y = LabelEncoder()\ny = labelencoder_Y.fit_transform(y.ravel())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier.fit(X_train,y_train.ravel())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred=classifier.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Finding the confusion matrix and Accuracy_score**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix,accuracy_score\n\ncm=confusion_matrix(y_test,y_pred)\nAccuracy=accuracy_score(y_test,y_pred)\n\nprint(cm)\nprint(Accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nAccuracy=cross_val_score(classifier,X_train,y_train.ravel(),cv=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Accuracy","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Finding the Accuracy of the XGBooster**"},{"metadata":{"trusted":true},"cell_type":"code","source":"Accuracy.mean()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}